{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GPU 사용가능 -> True, GPU 사용불가 -> Flase\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('1. GPU 사용가능 -> True, GPU 사용불가 -> Flase')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. GPU 사용중 -> True, GPU 사용안함 -> Flase\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('2. GPU 사용중 -> True, GPU 사용안함 -> Flase')\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('3. 학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. GPU 이름 체크(cuda:0 에 연결된 그래픽 카드 기준)\n",
      "GeForce RTX 2080\n"
     ]
    }
   ],
   "source": [
    "print('4. GPU 이름 체크(cuda:0 에 연결된 그래픽 카드 기준)')\n",
    "print(torch.cuda.get_device_name()) # 'NVIDIA TITAN X (Pascal)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. 사용 가능 GPU 개수 체크\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('5. 사용 가능 GPU 개수 체크')\n",
    "print(torch.cuda.device_count()) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12855262601487122996\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6254821376\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16148553144929639205\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "True\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 사용\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\MyProject\\kobert\\kobert\\.cache\\kobert_v1.zip\n",
      "using cached model. c:\\MyProject\\kobert\\kobert\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델, Vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구글드라이브 연동\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chatbot_data = pd.read_excel('./data/한국어_단발성_대화_데이터셋.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>공포</th>\n",
       "      <th>5468</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16173</th>\n",
       "      <td>구린내가 진동하는 놈들은 확실히 순실이 내시....</td>\n",
       "      <td>분노</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>이걸 따로 학원가서 배운다고? 헐</td>\n",
       "      <td>놀람</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27056</th>\n",
       "      <td>아 연구대상감이다</td>\n",
       "      <td>중립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12239</th>\n",
       "      <td>순실네하고 조용히 살지 대통령은 왜 돼서 국민 괴롭히니 나쁜x</td>\n",
       "      <td>분노</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>이러는게정말 올바른 길 가는건지 궁금합니다..</td>\n",
       "      <td>공포</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>27일이 아니라 오늘이라도 떠나세요!</td>\n",
       "      <td>공포</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34082</th>\n",
       "      <td>그네~하야하는 그날까지 ~난 토요일 마다~광화문 간다~~</td>\n",
       "      <td>혐오</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12964</th>\n",
       "      <td>그리고 1원하나 챙긴게 없다고?</td>\n",
       "      <td>분노</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17925</th>\n",
       "      <td>아 혼란스럽습니다</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>돈없는 사람들 죽어라죽어라하는구나!</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Sentence Emotion  Unnamed: 2  Unnamed: 3  \\\n",
       "16173        구린내가 진동하는 놈들은 확실히 순실이 내시....      분노         NaN         NaN   \n",
       "10785                  이걸 따로 학원가서 배운다고? 헐      놀람         NaN         NaN   \n",
       "27056                           아 연구대상감이다      중립         NaN         NaN   \n",
       "12239  순실네하고 조용히 살지 대통령은 왜 돼서 국민 괴롭히니 나쁜x      분노         NaN         NaN   \n",
       "4081            이러는게정말 올바른 길 가는건지 궁금합니다..      공포         NaN         NaN   \n",
       "2581                 27일이 아니라 오늘이라도 떠나세요!      공포         NaN         NaN   \n",
       "34082     그네~하야하는 그날까지 ~난 토요일 마다~광화문 간다~~      혐오         NaN         NaN   \n",
       "12964                   그리고 1원하나 챙긴게 없다고?      분노         NaN         NaN   \n",
       "17925                           아 혼란스럽습니다      슬픔         NaN         NaN   \n",
       "19564                 돈없는 사람들 죽어라죽어라하는구나!      슬픔         NaN         NaN   \n",
       "\n",
       "       Unnamed: 4   공포  5468  \n",
       "16173         NaN  NaN   NaN  \n",
       "10785         NaN  NaN   NaN  \n",
       "27056         NaN  NaN   NaN  \n",
       "12239         NaN  NaN   NaN  \n",
       "4081          NaN  NaN   NaN  \n",
       "2581          NaN  NaN   NaN  \n",
       "34082         NaN  NaN   NaN  \n",
       "12964         NaN  NaN   NaN  \n",
       "17925         NaN  NaN   NaN  \n",
       "19564         NaN  NaN   NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"공포\"), 'Emotion'] = 0  #공포 => 0\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"놀람\"), 'Emotion'] = 1  #놀람 => 1\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"분노\"), 'Emotion'] = 2  #분노 => 2\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"슬픔\"), 'Emotion'] = 3  #슬픔 => 3\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"중립\"), 'Emotion'] = 4  #중립 => 4\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"행복\"), 'Emotion'] = 5  #행복 => 5\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"혐오\"), 'Emotion'] = 6  #혐오 => 6\n",
    "\n",
    "data_list = []\n",
    "for q, label in zip(chatbot_data['Sentence'], chatbot_data['Emotion'])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['언니 동생으로 부르는게 맞는 일인가요..??', '0']\n",
      "['기술적으로도 아직도 해체해서 다시 완벽히 돌려놓는게 어려운데 해체를한다고?', '1']\n",
      "['당연히 그렇게 해야지 우리나라도 판매를 중단하라', '2']\n",
      "['그거들은 뒤부터 미치겠어요...', '3']\n",
      "['최악의 상황중 그나마 나은 방법이네. 기분은 잡치겠지만', '4']\n",
      "['  요리하는것이 숙제하는것처럼 힘든저에게 용기나게 해주시고 할수 있을것같은 희망을 주셔서감사합니다!!', '5']\n",
      "['와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요', '6']\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0])\n",
    "print(data_list[6000])\n",
    "print(data_list[12000])\n",
    "print(data_list[18000])\n",
    "print(data_list[24000])\n",
    "print(data_list[30000])\n",
    "print(data_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train & test 데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28945\n",
      "9649\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 32\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\MyProject\\kobert\\kobert\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 1189,  517, 6188, 7245, 7063,  517,  463, 3486, 7836, 5966,\n",
       "        1698,  517, 6188, 7245, 7063,  517,  463, 1281, 7870, 1801, 6885,\n",
       "        7088, 5966, 1698, 5837, 5837,  517, 6188, 7245, 6398, 6037, 7063,\n",
       "         517,  463,  517,  463,  517,  364,  517,  364,    3,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " array(42),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2059136b370>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    \n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\MyProject\\kobert\\kobert\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "def predict(predict_sentence):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "\n",
    "            if np.argmax(logits) == 0:\n",
    "                test_eval.append(\"공포가\")\n",
    "            elif np.argmax(logits) == 1:\n",
    "                test_eval.append(\"놀람이\")\n",
    "            elif np.argmax(logits) == 2:\n",
    "                test_eval.append(\"분노가\")\n",
    "            elif np.argmax(logits) == 3:\n",
    "                test_eval.append(\"슬픔이\")\n",
    "            elif np.argmax(logits) == 4:\n",
    "                test_eval.append(\"중립이\")\n",
    "            elif np.argmax(logits) == 5:\n",
    "                test_eval.append(\"행복이\")\n",
    "            elif np.argmax(logits) == 6:\n",
    "                test_eval.append(\"혐오가\")\n",
    "\n",
    "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 17604, 18740, 2968, 10428, 12060) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:986\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 986\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\multiprocessing\\queues.py:108\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\MyProject\\kobert\\kobert\\test.ipynb 셀 27\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m sentence \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=5'>6</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=6'>7</a>\u001b[0m predict(sentence)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\MyProject\\kobert\\kobert\\test.ipynb 셀 27\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(predict_sentence)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=10'>11</a>\u001b[0m test_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(another_test, batch_size\u001b[39m=\u001b[39mbatch_size, num_workers\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, (token_ids, valid_length, segment_ids, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=15'>16</a>\u001b[0m     token_ids \u001b[39m=\u001b[39m token_ids\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/MyProject/kobert/kobert/test.ipynb#ch0000026?line=16'>17</a>\u001b[0m     segment_ids \u001b[39m=\u001b[39m segment_ids\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1182\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1181\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1182\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1185\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1148\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1147\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1148\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1149\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1150\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:999\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    998\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m--> 999\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1001\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 17604, 18740, 2968, 10428, 12060) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "#질문 무한반복하기! 0 입력시 종료\n",
    "end = 1\n",
    "while end == 1 :\n",
    "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
    "    if sentence == 0 :\n",
    "        break\n",
    "    predict(sentence)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('readvice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82e657652c1f559b98fb141e76bcce2ec0f3958c3a6000b4409466ee456e5f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
