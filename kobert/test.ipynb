{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. GPU 사용가능 -> True, GPU 사용불가 -> Flase\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print('1. GPU 사용가능 -> True, GPU 사용불가 -> Flase')\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. GPU 사용중 -> True, GPU 사용안함 -> Flase\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('2. GPU 사용중 -> True, GPU 사용안함 -> Flase')\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. 학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('3. 학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. GPU 이름 체크(cuda:0 에 연결된 그래픽 카드 기준)\n",
      "GeForce RTX 2080\n"
     ]
    }
   ],
   "source": [
    "print('4. GPU 이름 체크(cuda:0 에 연결된 그래픽 카드 기준)')\n",
    "print(torch.cuda.get_device_name()) # 'NVIDIA TITAN X (Pascal)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. 사용 가능 GPU 개수 체크\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('5. 사용 가능 GPU 개수 체크')\n",
    "print(torch.cuda.device_count()) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17804809698252014510\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6254821376\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15180983728893116146\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "True\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kobert\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 사용\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\MyProject\\yolov5\\.cache\\kobert_v1.zip[██████████████████████████████████████████████████]\n",
      "c:\\MyProject\\yolov5\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델, Vocabulary 불러오기\n",
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#구글드라이브 연동\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chatbot_data = pd.read_excel('./kobert/data/한국어_단발성_대화_데이터셋.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>공포</th>\n",
       "      <th>5468</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24071</th>\n",
       "      <td>비가 오긴 했나요?ㅡ ㅡ</td>\n",
       "      <td>중립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28242</th>\n",
       "      <td>추카추카</td>\n",
       "      <td>행복</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30492</th>\n",
       "      <td>실시간으로 어플 통해 매장 안 상황 확인도 가능하고24시간 긴급출동서비스도 있어서 ...</td>\n",
       "      <td>행복</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28955</th>\n",
       "      <td>웃다 웃다 눈물흘렸네요...</td>\n",
       "      <td>행복</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17379</th>\n",
       "      <td>이십대중반임애 갖으려고 일도 그만뒀는데 안생기니까 겁나 초조해지뮤ㅠ</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26374</th>\n",
       "      <td>솔직히 주체측 추산보다 경찰 추산이 더 현실적인거 아닌가?</td>\n",
       "      <td>중립</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20057</th>\n",
       "      <td>내가 선택하고 저지른 일인데 오빠가 차가울때마다 너무 힘드네요</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18278</th>\n",
       "      <td>이틀동안장례식장 다녀오느라잠도못잣다..</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>진짜 대단하다대한민국 대통령이란 사람이야매를받다니 진짜 대단하다어찌 이걸몰랐지?</td>\n",
       "      <td>놀람</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34398</th>\n",
       "      <td>삼성알바들 삼성 실드치로 왔네 ㅋㅋㅋㅋㅋ</td>\n",
       "      <td>혐오</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Emotion  Unnamed: 2  \\\n",
       "24071                                      비가 오긴 했나요?ㅡ ㅡ      중립         NaN   \n",
       "28242                                               추카추카      행복         NaN   \n",
       "30492  실시간으로 어플 통해 매장 안 상황 확인도 가능하고24시간 긴급출동서비스도 있어서 ...      행복         NaN   \n",
       "28955                                    웃다 웃다 눈물흘렸네요...      행복         NaN   \n",
       "17379              이십대중반임애 갖으려고 일도 그만뒀는데 안생기니까 겁나 초조해지뮤ㅠ      슬픔         NaN   \n",
       "26374                   솔직히 주체측 추산보다 경찰 추산이 더 현실적인거 아닌가?      중립         NaN   \n",
       "20057                 내가 선택하고 저지른 일인데 오빠가 차가울때마다 너무 힘드네요      슬픔         NaN   \n",
       "18278                              이틀동안장례식장 다녀오느라잠도못잣다..      슬픔         NaN   \n",
       "8031        진짜 대단하다대한민국 대통령이란 사람이야매를받다니 진짜 대단하다어찌 이걸몰랐지?      놀람         NaN   \n",
       "34398                             삼성알바들 삼성 실드치로 왔네 ㅋㅋㅋㅋㅋ      혐오         NaN   \n",
       "\n",
       "       Unnamed: 3  Unnamed: 4   공포  5468  \n",
       "24071         NaN         NaN  NaN   NaN  \n",
       "28242         NaN         NaN  NaN   NaN  \n",
       "30492         NaN         NaN  NaN   NaN  \n",
       "28955         NaN         NaN  NaN   NaN  \n",
       "17379         NaN         NaN  NaN   NaN  \n",
       "26374         NaN         NaN  NaN   NaN  \n",
       "20057         NaN         NaN  NaN   NaN  \n",
       "18278         NaN         NaN  NaN   NaN  \n",
       "8031          NaN         NaN  NaN   NaN  \n",
       "34398         NaN         NaN  NaN   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"공포\"), 'Emotion'] = 0  #공포 => 0\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"놀람\"), 'Emotion'] = 1  #놀람 => 1\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"분노\"), 'Emotion'] = 2  #분노 => 2\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"슬픔\"), 'Emotion'] = 3  #슬픔 => 3\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"중립\"), 'Emotion'] = 4  #중립 => 4\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"행복\"), 'Emotion'] = 5  #행복 => 5\n",
    "chatbot_data.loc[(chatbot_data['Emotion'] == \"혐오\"), 'Emotion'] = 6  #혐오 => 6\n",
    "\n",
    "data_list = []\n",
    "for q, label in zip(chatbot_data['Sentence'], chatbot_data['Emotion'])  :\n",
    "    data = []\n",
    "    data.append(q)\n",
    "    data.append(str(label))\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['언니 동생으로 부르는게 맞는 일인가요..??', '0']\n",
      "['기술적으로도 아직도 해체해서 다시 완벽히 돌려놓는게 어려운데 해체를한다고?', '1']\n",
      "['당연히 그렇게 해야지 우리나라도 판매를 중단하라', '2']\n",
      "['그거들은 뒤부터 미치겠어요...', '3']\n",
      "['최악의 상황중 그나마 나은 방법이네. 기분은 잡치겠지만', '4']\n",
      "['  요리하는것이 숙제하는것처럼 힘든저에게 용기나게 해주시고 할수 있을것같은 희망을 주셔서감사합니다!!', '5']\n",
      "['와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요', '6']\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0])\n",
    "print(data_list[6000])\n",
    "print(data_list[12000])\n",
    "print(data_list[18000])\n",
    "print(data_list[24000])\n",
    "print(data_list[30000])\n",
    "print(data_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train & test 데이터로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28945\n",
      "9649\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 1\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 2\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. c:\\MyProject\\yolov5\\.cache\\kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "#토큰화\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 1189,  517, 6188, 7245, 7063,  517,  463, 3486, 7836, 5966,\n",
       "        1698,  517, 6188, 7245, 7063,  517,  463, 1281, 7870, 1801, 6885,\n",
       "        7088, 5966, 1698, 5837, 5837,  517, 6188, 7245, 6398, 6037, 7063,\n",
       "         517,  463,  517,  463,  517,  364,  517,  364,    3,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1]),\n",
       " array(42),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=7,   ##클래스 수 조정##\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\readvice\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x17052654970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT 모델 불러오기\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "\n",
    "#optimizer와 schedule 설정\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "#정확도 측정을 위한 함수 정의\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n",
    "    \n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('readvice')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82e657652c1f559b98fb141e76bcce2ec0f3958c3a6000b4409466ee456e5f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
